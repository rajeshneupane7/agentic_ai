{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "bbb24f81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ids': [['What are the latest dairy farm_1']], 'embeddings': None, 'documents': [['In 2025 , dairy producers are rapidly embracing technologies that optimize feeding regimes, bolster animal health, and maximize milk production, including:']], 'uris': None, 'included': ['metadatas', 'documents', 'distances'], 'data': None, 'metadatas': [[None]], 'distances': [[0.45516690611839294]]}\n",
      "üìÇ Answering from DB memory...\n",
      "\n",
      "ü§ñ Final Answer:\n",
      " Based on current trends and advancements in the dairy industry, some of the most innovative dairy technology in 2025 include:\n",
      "\n",
      "1. **Artificial Intelligence (AI) and Machine Learning (ML) for Predictive Analytics**: AI-powered systems that analyze data from various sources, such as sensor readings, cow behavior, and production records, to predict milk production, detect potential health issues, and optimize feeding regimes.\n",
      "2. **Precision Feeding Systems with Automated Nutrition Management**: Advanced computerized feeding systems that use machine learning algorithms to adjust feed rations based on individual animal needs, optimizing nutrition for improved growth rates, fertility, and overall herd health.\n",
      "3. **Genomics and Epigenetics for Genetic Selection**: Genomic analysis of dairy cattle to identify genetic markers associated with desirable traits, enabling breeders to make data-driven selections that boost milk production, improve fertility, and enhance overall herd performance.\n",
      "4. **Automated Milking Systems (AMS) with Integrated Analytics**: Advanced AMS systems that integrate robotic milking, real-time monitoring, and advanced data analytics to optimize milk production, reduce losses, and enhance cow comfort.\n",
      "5. **Virtual Reality (VR) Training for Dairy Farmers**: Immersive VR experiences that simulate farm environments, allowing farmers to practice decision-making and training in a controlled setting, reducing the need for hands-on experience.\n",
      "\n",
      "These innovative technologies are expected to transform the dairy industry by optimizing feeding regimes, improving animal health, and maximizing milk production.\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.llms import Ollama\n",
    "from ddgs import DDGS\n",
    "import chromadb\n",
    "# Load your local Ollama model\n",
    "llm = Ollama(model=\"llama3.2\")  \n",
    "\n",
    "hroma_client = chromadb.PersistentClient(path=\"./web_memory\")\n",
    "collection = chroma_client.get_or_create_collection(\"web_knowledge\")\n",
    "\n",
    "# --- Web Search Function ---\n",
    "def web_search(query, n=2):\n",
    "    with DDGS() as ddgs:\n",
    "        results = [r for r in ddgs.text(query, max_results=n)]\n",
    "    return results\n",
    "\n",
    "# --- Agent Decision Function ---\n",
    "def agent_answer(query):\n",
    "    # Step 1: Check DB for past info\n",
    "    matches = collection.query(query_texts=[query], n_results=1)\n",
    "    print(matches)\n",
    "    if matches[\"documents\"] and any(matches[\"documents\"][0]):\n",
    "        context = \"\\n\".join(matches[\"documents\"][0])\n",
    "        print(\"üìÇ Answering from DB memory...\")\n",
    "    else:\n",
    "        # Step 2: If no DB match, do web search\n",
    "        print(\"üåê Doing web search...\")\n",
    "        results = web_search(query, n=3)\n",
    "        context = \"\\n\".join([r[\"body\"] for r in results])\n",
    "        # Store in DB for future use\n",
    "        for i, r in enumerate(results):\n",
    "            collection.add(\n",
    "                documents=[r[\"body\"]],\n",
    "                ids=[f\"{query[:30]}_{i}\"]  # unique ID\n",
    "            )\n",
    "\n",
    "    # Step 3: Ask Ollama with context\n",
    "    prompt = f\"\"\"\n",
    "    You are a research assistant.\n",
    "    The user asked: {query}\n",
    "\n",
    "    Context (from memory or web search):\n",
    "    {context}\n",
    "\n",
    "    Please provide a helpful and concise answer.\n",
    "    \"\"\"\n",
    "    return llm.invoke(prompt)\n",
    "\n",
    "# --- Example Run ---\n",
    "question = \"which is most innovative dairy technology in 2025?\"\n",
    "answer = agent_answer(question)\n",
    "print(\"\\nü§ñ Final Answer:\\n\", answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "4be389ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.llms import Ollama\n",
    "from ddgs import DDGS\n",
    "import chromadb\n",
    "import spacy\n",
    "\n",
    "# Load your local Ollama model\n",
    "llm = Ollama(model=\"llama3.2\")  \n",
    "\n",
    "chroma_client = chromadb.PersistentClient(path=\"./web_memory\")\n",
    "collection = chroma_client.get_or_create_collection(\"web_knowledge\")\n",
    "\n",
    "# --- Initialize spaCy ---\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "def extract_keywords(text):\n",
    "    \"\"\"Extract lemmas (keywords) using spaCy.\"\"\"\n",
    "    doc = nlp(text)\n",
    "    return {token.lemma_.lower() for token in doc if token.is_alpha and not token.is_stop}\n",
    "\n",
    "# --- Web Search Function ---\n",
    "def web_search(query, n=5):\n",
    "    with DDGS() as ddgs:\n",
    "        results = [r for r in ddgs.text(query, max_results=n)]\n",
    "    return results\n",
    "\n",
    "# --- Agent Decision Function ---\n",
    "def agent_answer(query):\n",
    "    query_keywords = extract_keywords(query)\n",
    "\n",
    "    # Step 1: Check DB for past info\n",
    "    matches = collection.query(query_texts=[query], n_results=1)\n",
    "    context = \"\"\n",
    "    use_db = False\n",
    "\n",
    "    if matches[\"documents\"] and any(matches[\"documents\"][0]):\n",
    "        candidate_text = \" \".join(matches[\"documents\"][0])\n",
    "        candidate_keywords = extract_keywords(candidate_text)\n",
    "\n",
    "        overlap = query_keywords.intersection(candidate_keywords)\n",
    "        print(f\"üîë Keyword overlap: {len(overlap)}\")\n",
    "\n",
    "        if len(overlap) >= 3:  # ‚úÖ Require at least 5 keyword matches\n",
    "            context = candidate_text\n",
    "            use_db = True\n",
    "            print(\"üìÇ Answering from DB memory...\")\n",
    "    \n",
    "    if not use_db:\n",
    "        # Step 2: If no strong DB match, do web search\n",
    "        print(\"üåê Doing web search...\")\n",
    "        results = web_search(query, n=3)\n",
    "        context = \"\\n\".join([r[\"body\"] for r in results])\n",
    "        # Store in DB for future use\n",
    "        for i, r in enumerate(results):\n",
    "            collection.add(\n",
    "                documents=[r[\"body\"]],\n",
    "                ids=[f\"{query[:30]}_{i}\"]  # unique ID\n",
    "            )\n",
    "\n",
    "    # Step 3: Ask Ollama with context\n",
    "    prompt = f\"\"\"\n",
    "    You are a research assistant.\n",
    "    The user asked: {query}\n",
    "\n",
    "    Context (from memory or web search):\n",
    "    {context}\n",
    "\n",
    "    Please provide a helpful and concise answer.\n",
    "    \"\"\"\n",
    "    return llm.invoke(prompt)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "cc912cf3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîë Keyword overlap: 1\n",
      "üåê Doing web search...\n",
      "\n",
      "ü§ñ Final Answer:\n",
      " Based on the latest technological trends in dairy farming, I can conclude that one of the most popular dairy technologies used in everyday farming is Automated Milking Systems (AMS). AMS uses robotic milking machines to milk cows 24/7, reducing labor costs and increasing efficiency. Additionally, electronic sensors such as activity monitors help detect when cows are in heat, improving reproductive health.\n",
      "\n",
      "This technology has become increasingly common on modern dairy farms due to its ability to optimize milk production while also promoting animal welfare and environmental sustainability.\n"
     ]
    }
   ],
   "source": [
    "question = \"which is the most popular dairy technolgy used in everyday farming,?\"\n",
    "answer = agent_answer(question)\n",
    "print(\"\\nü§ñ Final Answer:\\n\", answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "8c2a6da0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Milk Yield per Cow:\n",
      "cow_id\n",
      "0      9.767582\n",
      "1      9.445007\n",
      "2      9.735094\n",
      "3      9.645850\n",
      "4      9.981165\n",
      "5     10.176560\n",
      "6      9.708028\n",
      "7     10.026985\n",
      "8     10.038964\n",
      "9      9.703181\n",
      "10     9.759811\n",
      "11     9.358437\n",
      "12     9.966342\n",
      "13     9.764467\n",
      "14     9.419822\n",
      "15     9.967757\n",
      "16    10.170426\n",
      "17    10.014831\n",
      "18    10.298662\n",
      "19     9.102033\n",
      "Name: milk_yield, dtype: float64\n",
      "\n",
      "Unique Cow IDs: 20\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from langchain_community.llms import Ollama\n",
    "\n",
    "# Initialize LLM\n",
    "llm = Ollama(model=\"llama3.2\")\n",
    "\n",
    "# Directory containing CSV/Excel files\n",
    "DATA_DIR = \"./data_files\"\n",
    "\n",
    "# Step 1: List relevant files\n",
    "def find_csv_files(keyword=None):\n",
    "    files = [f for f in os.listdir(DATA_DIR) if f.endswith((\".csv\", \".xlsx\"))]\n",
    "    if keyword:\n",
    "        files = [f for f in files if keyword.lower() in f.lower()]\n",
    "    return files\n",
    "\n",
    "# Step 2: Infer schema\n",
    "def analyze_file(file_path):\n",
    "    df = pd.read_csv(file_path) if file_path.endswith(\".csv\") else pd.read_excel(file_path)\n",
    "    schema = {col: str(dtype) for col, dtype in df.dtypes.items()}\n",
    "    return df, schema\n",
    "\n",
    "# Step 3: Generate Python script from user query\n",
    "import re\n",
    "\n",
    "def generate_script(query, df_variable=\"df\"):\n",
    "    prompt = f\"\"\"\n",
    "    User query: {query}\n",
    "    Dataframe variable: {df_variable}\n",
    "    Columns and types: {df_variable}.dtypes.to_dict()\n",
    "    Generate a Python script using pandas to answer the query.Only respond with code as plain text without code block syntax around it\n",
    "    \"\"\"\n",
    "    response = llm.invoke(prompt)\n",
    "    \n",
    "    # Extract code inside ```python ... ``` or ``` ... ```\n",
    "    code_blocks = re.findall(r\"```(?:python)?\\n(.*?)```\", response, re.DOTALL)\n",
    "    if code_blocks:\n",
    "        script = code_blocks[0].strip()\n",
    "    else:\n",
    "        # If no code block detected, return entire response as fallback\n",
    "        script = response.strip()\n",
    "    \n",
    "    return script\n",
    "\n",
    "# Step 4: Execute safely\n",
    "def execute_script(script, df):\n",
    "    local_env = {\"df\": df}\n",
    "    exec(script, {}, local_env)\n",
    "    return local_env.get(\"result\", None)\n",
    "\n",
    "# Example usage\n",
    "files = find_csv_files(keyword=\"milk\")\n",
    "df, schema = analyze_file(os.path.join(DATA_DIR, files[0]))\n",
    "script = generate_script(\"Compute average milk yield per cow, unique cow id, total unique cow id\", df_variable=\"df\")\n",
    "result = execute_script(script, df)\n",
    "print(result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "c49982de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cow_id\n",
      "0      9.767582\n",
      "1      9.445007\n",
      "2      9.735094\n",
      "3      9.645850\n",
      "4      9.981165\n",
      "5     10.176560\n",
      "6      9.708028\n",
      "7     10.026985\n",
      "8     10.038964\n",
      "9      9.703181\n",
      "10     9.759811\n",
      "11     9.358437\n",
      "12     9.966342\n",
      "13     9.764467\n",
      "14     9.419822\n",
      "15     9.967757\n",
      "16    10.170426\n",
      "17    10.014831\n",
      "18    10.298662\n",
      "19     9.102033\n",
      "Name: milk_yield, dtype: float64\n",
      "\n",
      "ü§ñ Final Answer:\n",
      " None\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import re\n",
    "from langchain_community.llms import Ollama\n",
    "\n",
    "# Initialize LLM once\n",
    "llm = Ollama(model=\"llama3.2\")\n",
    "\n",
    "def run_query(data_path, query, keyword=None):\n",
    "    \"\"\"\n",
    "    Process CSV/Excel data files with an LLM-generated pandas script.\n",
    "    \n",
    "    Args:\n",
    "        data_path (str): Path to directory containing data files.\n",
    "        query (str): Natural language query to answer.\n",
    "        keyword (str, optional): Filter files by keyword in filename.\n",
    "    \n",
    "    Returns:\n",
    "        Any: Result from executing the generated script (stored in variable 'result').\n",
    "    \"\"\"\n",
    "    \n",
    "    # Step 1: List files\n",
    "    files = [f for f in os.listdir(data_path) if f.endswith((\".csv\", \".xlsx\"))]\n",
    "    if keyword:\n",
    "        files = [f for f in files if keyword.lower() in f.lower()]\n",
    "    if not files:\n",
    "        raise FileNotFoundError(\"No matching CSV/Excel files found.\")\n",
    "\n",
    "    # Step 2: Load first matching file\n",
    "    file_path = os.path.join(data_path, files[0])\n",
    "    df = pd.read_csv(file_path) if file_path.endswith(\".csv\") else pd.read_excel(file_path)\n",
    "    \n",
    "    # Step 3: Ask LLM for script\n",
    "    prompt = f\"\"\"\n",
    "    User query: {query}\n",
    "    Dataframe variable: df\n",
    "    Columns and types: {df.dtypes.to_dict()}\n",
    "    Generate a Python script using pandas to answer the query.\n",
    "    Only respond with code as plain text without code block syntax.\n",
    "    \"\"\"\n",
    "    response = llm.invoke(prompt)\n",
    "\n",
    "    # Extract code from response\n",
    "    code_blocks = re.findall(r\"```(?:python)?\\n(.*?)```\", response, re.DOTALL)\n",
    "    script = code_blocks[0].strip() if code_blocks else response.strip()\n",
    "\n",
    "    # Step 4: Execute safely\n",
    "    local_env = {\"df\": df}\n",
    "    exec(script, {}, local_env)\n",
    "    return local_env.get(\"result\", None)\n",
    "\n",
    "# Example usage:\n",
    "DATA_DIR = \"./data_files\"\n",
    "query = \"Compute average milk yield per cow\"\n",
    "result = run_query(DATA_DIR, query, keyword=\"milk\")\n",
    "print(\"\\nü§ñ Final Answer:\\n\", result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "3a184763",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ü§ñ Final Answer:\n",
      " None\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "import pandas as pd\n",
    "from langchain_community.llms import Ollama\n",
    "\n",
    "# Initialize LLM\n",
    "llm = Ollama(model=\"llama3.2\")\n",
    "\n",
    "def agent_answer(question):\n",
    "    \"\"\"\n",
    "    Handle user query about datasets with automatic file selection and LLM script generation.\n",
    "    User only needs to provide the question.\n",
    "    \n",
    "    Args:\n",
    "        question (str): User's natural language question.\n",
    "    \n",
    "    Returns:\n",
    "        Any: Result from executing the generated pandas script (variable 'result').\n",
    "    \"\"\"\n",
    "    \n",
    "    # Data directory (fixed internally)\n",
    "    DATA_DIR = \"./data_files\"\n",
    "    \n",
    "    # Step 1: Infer keyword based on question\n",
    "    keyword = None\n",
    "    if \"milk\" in question.lower():\n",
    "        keyword = \"milk\"\n",
    "    \n",
    "    # Step 2: Find matching files\n",
    "    files = [f for f in os.listdir(DATA_DIR) if f.endswith((\".csv\", \".xlsx\"))]\n",
    "    if keyword:\n",
    "        files = [f for f in files if keyword.lower() in f.lower()]\n",
    "    if not files:\n",
    "        raise FileNotFoundError(f\"No matching files found for keyword '{keyword}'.\")\n",
    "    \n",
    "    # Step 3: Load first file\n",
    "    file_path = os.path.join(DATA_DIR, files[0])\n",
    "    df = pd.read_csv(file_path) if file_path.endswith(\".csv\") else pd.read_excel(file_path)\n",
    "    \n",
    "    # Step 4: Generate script using LLM\n",
    "    prompt = f\"\"\"\n",
    "    User query: {question}\n",
    "    Dataframe variable: df\n",
    "    Columns and types: {df.dtypes.to_dict()}\n",
    "    Generate a Python script using pandas to answer the query.\n",
    "    Only respond with code as plain text without code block syntax or examples\n",
    "    \"\"\"\n",
    "    response = llm.invoke(prompt)\n",
    "    \n",
    "    # Extract code from response\n",
    "    code_blocks = re.findall(r\"```(?:python)?\\n(.*?)```\", response, re.DOTALL)\n",
    "    script = code_blocks[0].strip() if code_blocks else response.strip()\n",
    "    \n",
    "    # Step 5: Execute safely\n",
    "    local_env = {\"df\": df}\n",
    "    exec(script, {}, local_env)\n",
    "    \n",
    "    return local_env.get(\"result\", None)\n",
    "\n",
    "# ---------------- Example usage ----------------\n",
    "question = \"What is the average milk production per cow?\"\n",
    "result = ask_llm(question)\n",
    "print(\"\\nü§ñ Final Answer:\\n\", result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "a677c220",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cow_id\n",
      "0      9.767582\n",
      "1      9.445007\n",
      "2      9.735094\n",
      "3      9.645850\n",
      "4      9.981165\n",
      "5     10.176560\n",
      "6      9.708028\n",
      "7     10.026985\n",
      "8     10.038964\n",
      "9      9.703181\n",
      "10     9.759811\n",
      "11     9.358437\n",
      "12     9.966342\n",
      "13     9.764467\n",
      "14     9.419822\n",
      "15     9.967757\n",
      "16    10.170426\n",
      "17    10.014831\n",
      "18    10.298662\n",
      "19     9.102033\n",
      "Name: milk_yield, dtype: float64\n",
      "\n",
      "ü§ñ Final Answer:\n",
      " None\n"
     ]
    }
   ],
   "source": [
    "question = \"What is the average milk production for each cow?\"\n",
    "result = agent_answer(question)\n",
    "print(\"\\nü§ñ Final Answer:\\n\", result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c439fcdd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "basic_stat",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
